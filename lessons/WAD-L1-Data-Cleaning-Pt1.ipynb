{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [AHA! Activity Health Analytics](http://casas.wsu.edu/)\n",
    "[Center for Advanced Studies of Adaptive Systems (CASAS)](http://casas.wsu.edu/)\n",
    "\n",
    "[Washington State University](https://wsu.edu)\n",
    "# L1 Data Cleaning: Part 1\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this lesson, participants should have an understanding of:\n",
    "* Data cleaning \n",
    "* Real-world applications of data cleaning\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* [Pandas website](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Overview\n",
    "Data analysts spend a surprising amount of time preparing data for analysis. In fact, a survey was conducted found that cleaning big data is the most time-consuming and least enjoyable task data scientists do!\n",
    "<img src=\"https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg\" width=\"700\">\n",
    "(image from [https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg](https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg))\n",
    "\n",
    "Data preparation includes, but is not limited to, tasks such as:\n",
    "* Loading data into an appropriate data structure\n",
    "* Merging multiple data sets\n",
    "* Cleaning the data\n",
    "    * Reshaping data, transforming data, changing data type\n",
    "    * Replacing values, removing duplicates\n",
    "    * Performing data binning/discretization\n",
    "    * Handling missing values\n",
    "    * Detecting outliers\n",
    "    * Standardizing/scaling data\n",
    "* Many others!\n",
    "\n",
    "### Missing Values\n",
    "It is not uncommon to have datasets with missing values. Missing values are usually coded as an out of range value, such as an empty string in a text field, -1 in a numeric field that is normally positive, or 0 in a numeric field that cannot take on the value of 0. In the Scipy ecosystem, the common value `NaN` (not a number) is used to denote missing data. There is support in the Scipy libraries to handle `NaN` specially. For example, the Pandas function [`isnull()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html) returns a Boolean array detecting the `NaN` values element-wise and [`dropna()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html) removes `NaN` values from a series or data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0    0.0\n",
      "1    NaN\n",
      "2    2.0\n",
      "3    3.0\n",
      "4    4.0\n",
      "5    NaN\n",
      "6    6.0\n",
      "7    7.0\n",
      "8    8.0\n",
      "9    9.0\n",
      "dtype: float64\n",
      "0    0.0\n",
      "2    2.0\n",
      "3    3.0\n",
      "4    4.0\n",
      "6    6.0\n",
      "7    7.0\n",
      "8    8.0\n",
      "9    9.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = np.arange(0, 10)\n",
    "ser = pd.Series(x)\n",
    "ser[1] = np.NaN\n",
    "ser[5] = np.NaN\n",
    "nans = ser.isnull()\n",
    "# count the number of missing values\n",
    "print(nans.sum())\n",
    "print(ser)\n",
    "ser.dropna(inplace=True)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can learn more about missing data by reading [Pandas website](https://pandas.pydata.org/pandas-docs/stable/missing_data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By learning how to use the Pandas library, we have the skills to perform many of the tasks listed above. In this lesson, we are going to focus on *data cleaning*, modifying the data to make it sufficiently accurate and structured to support the analysis you want to perform. To learn about data cleaning, we are going to clean data by working through an example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Example\n",
    "We are going to work with the [pd_hoa_activities.csv](https://raw.githubusercontent.com/gsprint23/aha/master/lessons/files/pd_hoa_activities.csv) dataset. This dataset contains information from a smart home study where participants performed 9 activities of daily living (ADLs) in a smart home environment:\n",
    "1. Water plants\n",
    "1. Fill medication dispenser\n",
    "1. Wash counter top\n",
    "1. Sweep and dust\n",
    "1. Cook\n",
    "1. Wash hands\n",
    "1. Perform the [Timed Up and Go (TUG)](http://www.rehabmeasures.org/Lists/RehabMeasures/DispForm.aspx?ID=903) test\n",
    "1. Perform TUG with questions being asked\n",
    "1. A day out task\n",
    "\n",
    "Note: you can read more about the design of this study and the various tasks in [Cook et al., 2015](http://ieeexplore.ieee.org/document/7181652/). \n",
    "\n",
    "The activities were timed and the duration is recorded for each participant in the dataset. The participants of the study include individual's with Parkinson's disease (PD) and age-matched, healthy older adults (HOA). For each participant in the study, the dataset includes a participant id (pid), age, and their class (PD or HOA). The data has been de-identified. For the purposes of our analysis today, we are interested in aggregating this data into PD and HOA groups to investigate the effect of PD on older adult's ability to perform the above tasks.\n",
    "\n",
    "Here is a sample of the format of the data:\n",
    "\n",
    "|pid|task|duration|age|class|\n",
    "|-|-|-|-|-|\n",
    "|0|1|146|72|HOA|\n",
    "|0|2|210|72|HOA|\n",
    "|0|3|241|72|HOA|\n",
    "|0|4|328|72|HOA|\n",
    "|0|5|229|72|HOA|\n",
    "|0|6|38|72|HOA|\n",
    "|0|7|10|72|HOA|\n",
    "|0|8|10|72|HOA|\n",
    "|0|dot|680|72|HOA|\n",
    "|1|1|63|54|HOA|\n",
    "|...|...|...|...|...|\n",
    "\n",
    "Let's take a look at each column in the data and how the data needs to be cleaned:\n",
    "* pid (integer): Index of the dataset. Counting numbers starting at 0.\n",
    "* task (integer): ID of the task the patient performed.\n",
    "    * Clean: Decode the integer task label to the plain text string task label.\n",
    "    * Example: 1 will be decoded to \"Water plants\".\n",
    "* duration (integer): Number of seconds it took the participant to perform the task.\n",
    "    * Clean: Ensure this data is a numeric data type.\n",
    "* age (integer): Age of the participant.\n",
    "    * Clean: Ensure this data is a numeric data type.\n",
    "* class (string): Population the participant belongs to: HOA or PD.\n",
    "\n",
    "### Load the Data\n",
    "First we are going to load the data into a `pandas` `DataFrame` object. The header row is the first row in the file. We are not going to set an index column for the data because there is not a column in the csv file that contains unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(675, 5)\n",
      "Number of participants: 75\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fname = r\"files\\pd_hoa_activities.csv\"\n",
    "df = pd.read_csv(fname, header=0)\n",
    "print(df.shape)\n",
    "print(\"Number of participants:\", df.shape[0] // 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data\n",
    "Now, let's take a look at some of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pid task duration  age class\n",
      "0    0    1      146   72   HOA\n",
      "1    0    2      210   72   HOA\n",
      "2    0    3      241   72   HOA\n",
      "3    0    4      328   72   HOA\n",
      "4    0    5      229   72   HOA\n",
      "     pid task duration  age class\n",
      "670   74    5      235   78    PD\n",
      "671   74    6       41   78    PD\n",
      "672   74    7       11   78    PD\n",
      "673   74    8        9   78    PD\n",
      "674   74  dot     1532   78    PD\n",
      "     pid task duration  age class\n",
      "660   73    4       30   70    PD\n",
      "661   73    5      666   70    PD\n",
      "662   73    6      162   70    PD\n",
      "663   73    7        ?   70    PD\n",
      "664   73    8        ?   70    PD\n",
      "665   73  dot        ?   70    PD\n",
      "666   74    1      180   78    PD\n",
      "667   74    2      254   78    PD\n",
      "668   74    3      280   78    PD\n",
      "669   74    4      417   78    PD\n",
      "   pid task duration  age class\n",
      "7    0    8       10   72   HOA\n",
      "8    0  dot      680   72   HOA\n",
      "9    1    1       63   54   hoa\n",
      "    pid task duration  age        class\n",
      "25    2    8       11   62  parkinson's\n",
      "26    2  dot      921   62  parkinson's\n",
      "27    3    1      178   57           PD\n"
     ]
    }
   ],
   "source": [
    "print(df.head(n=5))\n",
    "print(df.tail(n=5))\n",
    "print(df[660:670])\n",
    "print(df[7:10])\n",
    "print(df[25:28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only look at the first 5 rows and the last 5 rows of the dataset, the columns looks like it is well formed with no missing values; however, we see the class column has inconsistent labels for our two classes (HOA and PD) and for pids 663, 664, 665 (among others) there is a \"?\" denoting a missing value. In fact, if we count the number of \"?\" in the duration column, we see that there are 10 tasks with missing durations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(df[\"duration\"].value_counts()[\"?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next lesson, we will write code to handle these missing values, as well as clean other columns of this dataset."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
