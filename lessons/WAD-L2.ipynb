{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [AHA! Activity Health Analytics](http://casas.wsu.edu/)\n",
    "[Center for Advanced Studies of Adaptive Systems (CASAS)](http://casas.wsu.edu/)\n",
    "\n",
    "[Washington State University](https://wsu.edu)\n",
    "# L2 Data Cleaning: Part 2\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this lesson, participants should have an understanding of:\n",
    "* Data cleaning \n",
    "* Real-world applications of data cleaning\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* [Pandas website](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Continued\n",
    "We are going to continue working with the [pd_hoa_activities.csv](https://raw.githubusercontent.com/gsprint23/aha/master/lessons/files/pd_hoa_activities.csv) dataset. Let's load the data into a `pandas` `DataFrame` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fname = r\"files\\pd_hoa_activities.csv\"\n",
    "df = pd.read_csv(fname, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data\n",
    "Let's replace the \"?\" with `NaN` values so we can more easily detect the fields with missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.replace(\"?\", np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74    9\n",
      "18    9\n",
      "20    9\n",
      "21    9\n",
      "22    9\n",
      "23    9\n",
      "24    9\n",
      "25    9\n",
      "26    9\n",
      "27    9\n",
      "28    9\n",
      "29    9\n",
      "30    9\n",
      "31    9\n",
      "32    9\n",
      "33    9\n",
      "34    9\n",
      "19    9\n",
      "17    9\n",
      "36    9\n",
      "16    9\n",
      "1     9\n",
      "2     9\n",
      "3     9\n",
      "4     9\n",
      "5     9\n",
      "6     9\n",
      "7     9\n",
      "8     9\n",
      "9     9\n",
      "     ..\n",
      "63    9\n",
      "64    9\n",
      "65    9\n",
      "66    9\n",
      "67    9\n",
      "68    9\n",
      "69    9\n",
      "70    9\n",
      "71    9\n",
      "72    9\n",
      "57    9\n",
      "55    9\n",
      "38    9\n",
      "54    9\n",
      "39    9\n",
      "40    9\n",
      "41    9\n",
      "42    9\n",
      "43    9\n",
      "44    9\n",
      "45    9\n",
      "46    9\n",
      "47    9\n",
      "48    9\n",
      "49    9\n",
      "50    9\n",
      "51    9\n",
      "52    9\n",
      "53    9\n",
      "0     9\n",
      "Name: pid, dtype: int64\n",
      "Number of NaN: 0\n",
      "***********************************************************************\n",
      "\n",
      "dot    75\n",
      "2      75\n",
      "1      75\n",
      "8      75\n",
      "4      75\n",
      "5      75\n",
      "7      75\n",
      "6      75\n",
      "3      75\n",
      "Name: task, dtype: int64\n",
      "Number of NaN: 0\n",
      "***********************************************************************\n",
      "\n",
      "9       29\n",
      "10      20\n",
      "11      18\n",
      "8       17\n",
      "7       12\n",
      "13      10\n",
      "6        8\n",
      "12       7\n",
      "5        7\n",
      "42       6\n",
      "52       5\n",
      "15       5\n",
      "205      5\n",
      "222      5\n",
      "214      5\n",
      "201      5\n",
      "34       4\n",
      "65       4\n",
      "297      4\n",
      "255      4\n",
      "35       4\n",
      "178      4\n",
      "224      4\n",
      "216      4\n",
      "31       4\n",
      "61       4\n",
      "48       4\n",
      "207      3\n",
      "312      3\n",
      "38       3\n",
      "        ..\n",
      "17       1\n",
      "4648     1\n",
      "181      1\n",
      "1535     1\n",
      "203      1\n",
      "537      1\n",
      "182      1\n",
      "500      1\n",
      "3513     1\n",
      "318      1\n",
      "397      1\n",
      "868      1\n",
      "460      1\n",
      "1365     1\n",
      "1532     1\n",
      "106      1\n",
      "1272     1\n",
      "298      1\n",
      "4279     1\n",
      "77       1\n",
      "190      1\n",
      "401      1\n",
      "306      1\n",
      "1251     1\n",
      "171      1\n",
      "208      1\n",
      "447      1\n",
      "320      1\n",
      "2041     1\n",
      "601      1\n",
      "Name: duration, dtype: int64\n",
      "Number of NaN: 10\n",
      "***********************************************************************\n",
      "\n",
      "70    72\n",
      "72    36\n",
      "62    36\n",
      "64    36\n",
      "65    36\n",
      "68    36\n",
      "54    36\n",
      "67    27\n",
      "56    27\n",
      "57    27\n",
      "76    27\n",
      "59    27\n",
      "80    18\n",
      "55    18\n",
      "60    18\n",
      "61    18\n",
      "87    18\n",
      "81    18\n",
      "83    18\n",
      "77    18\n",
      "85     9\n",
      "69     9\n",
      "66     9\n",
      "86     9\n",
      "89     9\n",
      "63     9\n",
      "88     9\n",
      "73     9\n",
      "75     9\n",
      "78     9\n",
      "79     9\n",
      "93     9\n",
      "Name: age, dtype: int64\n",
      "Number of NaN: 0\n",
      "***********************************************************************\n",
      "\n",
      "HOA            396\n",
      "PD             189\n",
      "hoa             27\n",
      "healthy         27\n",
      "Parkinson's      9\n",
      "pd               9\n",
      "parkinson's      9\n",
      "Parkinson        9\n",
      "Name: class, dtype: int64\n",
      "Number of NaN: 0\n",
      "***********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    ser = df[col]\n",
    "    print(ser.value_counts())\n",
    "    print(\"Number of NaN:\", ser.isnull().sum())\n",
    "    print(\"***********************************************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our exploration of the data, we know there are 10 null values in the duration column that we need handle. There are a few ways we do this:\n",
    "1. Remove the row and/or participant's data with missing information\n",
    "1. Fill the missing values. One way to do this is by filling each missing value with the average of \"similar\" instances (e.g. same task, same class, similar age).\n",
    "1. Leave it alone for now. Handle it on a case by case basis in the later stages of the data analysis pipeline.\n",
    "\n",
    "We are going to remove the rows with missing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: (675, 5)\n",
      "After cleaning: (665, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before cleaning:\", df.shape)  \n",
    "df.dropna(inplace=True)\n",
    "index = np.arange(0, len(df))\n",
    "df.set_index(index, inplace=True)\n",
    "print(\"After cleaning:\", df.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode Task\n",
    "Now, let's decode the integer values associated with the task column by replacing them with a more human-readable text label. We will use a dictionary to story the integer to string mappings for task codes and replace the integers with the strings in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pid                       task duration  age class\n",
      "0     0               Water Plants      146   72   HOA\n",
      "1     0  Fill Medication Dispenser      210   72   HOA\n",
      "2     0            Wash Countertop      241   72   HOA\n",
      "3     0             Sweep and Dust      328   72   HOA\n",
      "4     0                       Cook      229   72   HOA\n",
      "5     0                 Wash Hands       38   72   HOA\n",
      "6     0                Perform TUG       10   72   HOA\n",
      "7     0    Perform TUG w/Questions       10   72   HOA\n",
      "8     0               Day Out Task      680   72   HOA\n",
      "9     1               Water Plants       63   54   hoa\n",
      "10    1  Fill Medication Dispenser      202   54   hoa\n"
     ]
    }
   ],
   "source": [
    "task_decoder = {\"1\": \"Water Plants\", \"2\": \"Fill Medication Dispenser\", \"3\": \"Wash Countertop\", \\\n",
    "               \"4\": \"Sweep and Dust\", \"5\": \"Cook\", \"6\": \"Wash Hands\", \"7\": \"Perform TUG\", \\\n",
    "               \"8\": \"Perform TUG w/Questions\", \"dot\": \"Day Out Task\"}\n",
    "\n",
    "def decode_task(df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    ser = df[\"task\"]\n",
    "    for key in task_decoder:\n",
    "        ser.replace(key, task_decoder[key], inplace=True)\n",
    "decode_task(df)\n",
    "print(df.head(n=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data frame now, we see that the task category is much more readable. This will be especially useful for generating plots with task labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Numeric Data Types\n",
    "Now, let's check out the data types for our two numeric columns, duration and age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"duration\"].dtype)\n",
    "print(df[\"age\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the age column is an integer type, but the duration column is an object type. This means that Pandas was unable to infer this column contained all integers when it was read in, which makes sense since we know there were \"?\"s in the duration column. Since we have replaced the \"?\" with `NaN`, let's convert it to integer now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "df[\"duration\"] = df[\"duration\"].astype(np.int)\n",
    "print(df[\"duration\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Class\n",
    "Lastly, we are going to clean the class column. This column is quite messy compared to the other columns we have worked with. We will use a simple rule based system to handle the various spellings and word choices that represent \"HOA\" and \"PD\".\n",
    "\n",
    "Note: If there are entries that we cannot classify as one of the above labels, we will overwrite the entry with a null value (`NaN`) to represent missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pid                       task  duration  age class\n",
      "0    0               Water Plants       146   72   HOA\n",
      "1    0  Fill Medication Dispenser       210   72   HOA\n",
      "2    0            Wash Countertop       241   72   HOA\n",
      "3    0             Sweep and Dust       328   72   HOA\n",
      "4    0                       Cook       229   72   HOA\n",
      "HOA    446\n",
      "PD     219\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def clean_class(df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    ser = df[\"class\"].copy()\n",
    "    \n",
    "    for i in range(0, len(ser), 1):\n",
    "        curr = str(ser[i])\n",
    "        curr = curr.lower()\n",
    "        if \"hoa\" in curr or \"healthy\" in curr:\n",
    "            ser[i] = \"HOA\"\n",
    "        elif \"pd\" in curr or \"parkinson\" in curr:\n",
    "            ser[i] = \"PD\"\n",
    "        else:\n",
    "            print(\"Unrecognized status: %d, %s\" %(i, ser[i]))\n",
    "            ser[i] = np.NaN\n",
    "        \n",
    "    df[\"class\"] = ser\n",
    "\n",
    "clean_class(df)\n",
    "print(df.head())\n",
    "print(df[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will write the cleaned data frame out to a new file. Our dataset is now cleaned and ready for use in the next step of our data analysis pipeline. Depending on what we want to do with the data, this could be continuing exploration by generating visualizations of the data, or perhaps scaling the features in preparation for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_fname = r\"files\\pd_hoa_activities_cleaned.csv\"\n",
    "df.to_csv(out_fname, index=False) # don't write out the index column"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
