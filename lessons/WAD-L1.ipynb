{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [AHA! Activity Health Analytics](http://casas.wsu.edu/)\n",
    "[Center for Advanced Studies of Adaptive Systems (CASAS)](http://casas.wsu.edu/)\n",
    "\n",
    "[Washington State University](https://wsu.edu)\n",
    "# L1 Data Cleaning\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this lesson, participants should have an understanding of:\n",
    "* Data cleaning \n",
    "* Real-world applications of data cleaning\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* [Pandas website](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Overview\n",
    "Data analysts spend a surprising amount of time preparing data for analysis. In fact, a survey was conducted found that cleaning big data is the most time-consuming and least enjoyable task data scientists do!\n",
    "<img src=\"http://blogs-images.forbes.com/gilpress/files/2016/03/Time-1200x511.jpg\" width=\"700\">\n",
    "(image from [http://blogs-images.forbes.com/gilpress/files/2016/03/Time-1200x511.jpg](http://blogs-images.forbes.com/gilpress/files/2016/03/Time-1200x511.jpg))\n",
    "\n",
    "Data preparation includes, but is not limited to, tasks such as:\n",
    "* Loading data into an appropriate data structure\n",
    "* Merging multiple data sets\n",
    "* Cleaning the data\n",
    "    * Reshaping data, transforming data, changing data type\n",
    "    * Replacing values, removing duplicates\n",
    "    * Performing data binning/discretization\n",
    "    * Handling missing values\n",
    "    * Detecting outliers\n",
    "    * Standardizing/scaling data\n",
    "* Many others!\n",
    "\n",
    "### Missing Values\n",
    "It is not uncommon to have datasets with missing values. Missing values are usually coded as an out of range value, such as an empty string in a text field, -1 in a numeric field that is normally positive, or 0 in a numeric field that cannot take on the value of 0. In the Scipy ecosystem, the common value `NaN` (not a number) is used to denote missing data. There is support in the Scipy libraries to handle `NaN` specially. For example, the Pandas function [`isnull()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html) returns a Boolean array detecting the `NaN` values element-wise and [`dropna()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html) removes `NaN` values from a series or data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0    0.0\n",
      "1    NaN\n",
      "2    2.0\n",
      "3    3.0\n",
      "4    4.0\n",
      "5    NaN\n",
      "6    6.0\n",
      "7    7.0\n",
      "8    8.0\n",
      "9    9.0\n",
      "dtype: float64\n",
      "0    0.0\n",
      "2    2.0\n",
      "3    3.0\n",
      "4    4.0\n",
      "6    6.0\n",
      "7    7.0\n",
      "8    8.0\n",
      "9    9.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = np.arange(0, 10)\n",
    "ser = pd.Series(x)\n",
    "ser[1] = np.NaN\n",
    "ser[5] = np.NaN\n",
    "nans = ser.isnull()\n",
    "# count the number of missing values\n",
    "print(nans.sum())\n",
    "print(ser)\n",
    "ser.dropna(inplace=True)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can learn more about missing data by reading [Pandas website](https://pandas.pydata.org/pandas-docs/stable/missing_data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By learning how to use the Pandas library, we have the skills to perform many of the tasks listed above. In this lesson, we are going to focus on *data cleaning*, modifying the data to make it sufficiently accurate and structured to support the analysis you want to perform. To learn about data cleaning, we are going to clean data by working through an example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Example\n",
    "We are going to work with the [pd_hoa_activities.csv](https://raw.githubusercontent.com/gsprint23/aha/master/lessons/files/pd_hoa_activities.csv) dataset. This dataset contains information from a smart home study where participants performed 9 activities of daily living (ADLs) in a smart home environment:\n",
    "1. Water plants\n",
    "1. Fill medication dispenser\n",
    "1. Wash counter top\n",
    "1. Sweep and dust\n",
    "1. Cook\n",
    "1. Wash hands\n",
    "1. Perform the [Timed Up and Go (TUG)](http://www.rehabmeasures.org/Lists/RehabMeasures/DispForm.aspx?ID=903) test\n",
    "1. Perform TUG with questions being asked\n",
    "1. A day out task\n",
    "\n",
    "Note: you can read more about the design of this study and the various tasks in [Cook et al., 2015](http://ieeexplore.ieee.org/document/7181652/). \n",
    "\n",
    "The activities were timed and the duration is recorded for each participant in the dataset. The participants of the study include individual's with Parkinson's disease (PD) and age-matched, healthy older adults (HOA). For each participant in the study, the dataset includes a participant id (pid), age, and their class (PD or HOA). The data has been de-identified. For the purposes of our analysis today, we are interested in aggregating this data into PD and HOA groups to investigate the effect of PD on older adult's ability to perform the above tasks.\n",
    "\n",
    "Here is a sample of the format of the data:\n",
    "\n",
    "|pid|task|duration|age|class|\n",
    "|-|-|-|-|-|\n",
    "|0|1|146|72|HOA|\n",
    "|0|2|210|72|HOA|\n",
    "|0|3|241|72|HOA|\n",
    "|0|4|328|72|HOA|\n",
    "|0|5|229|72|HOA|\n",
    "|0|6|38|72|HOA|\n",
    "|0|7|10|72|HOA|\n",
    "|0|8|10|72|HOA|\n",
    "|0|dot|680|72|HOA|\n",
    "|1|1|63|54|HOA|\n",
    "|...|...|...|...|...|\n",
    "\n",
    "Let's take a look at each column in the data and how the data needs to be cleaned:\n",
    "* pid (integer): Index of the dataset. Counting numbers starting at 0.\n",
    "* task (integer): ID of the task the patient performed.\n",
    "    * Clean: Decode the integer task label to the plain text string task label.\n",
    "    * Example: 1 will be decoded to \"Water plants\".\n",
    "* duration (integer): Number of seconds it took the participant to perform the task.\n",
    "    * Clean: Ensure this data is a numeric data type.\n",
    "* age (integer): Age of the participant.\n",
    "    * Clean: Ensure this data is a numeric data type.\n",
    "* class (string): Population the participant belongs to: HOA or PD.\n",
    "\n",
    "### Load the Data\n",
    "First we are going to load the data into a `pandas` `DataFrame` object. The header row is the first row in the file. We are not going to set an index column for the data because there is not a column in the csv file that contains unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(675, 5)\n",
      "Number of participants: 75\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fname = r\"files\\pd_hoa_activities.csv\"\n",
    "df = pd.read_csv(fname, header=0)\n",
    "print(df.shape)\n",
    "print(\"Number of participants:\", df.shape[0] // 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data\n",
    "Now, let's take a look at some of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pid task duration  age class\n",
      "0    0    1      146   72   HOA\n",
      "1    0    2      210   72   HOA\n",
      "2    0    3      241   72   HOA\n",
      "3    0    4      328   72   HOA\n",
      "4    0    5      229   72   HOA\n",
      "     pid task duration  age class\n",
      "670   74    5      235   78    PD\n",
      "671   74    6       41   78    PD\n",
      "672   74    7       11   78    PD\n",
      "673   74    8        9   78    PD\n",
      "674   74  dot     1532   78    PD\n",
      "     pid task duration  age class\n",
      "660   73    4       30   70    PD\n",
      "661   73    5      666   70    PD\n",
      "662   73    6      162   70    PD\n",
      "663   73    7        ?   70    PD\n",
      "664   73    8        ?   70    PD\n",
      "665   73  dot        ?   70    PD\n",
      "666   74    1      180   78    PD\n",
      "667   74    2      254   78    PD\n",
      "668   74    3      280   78    PD\n",
      "669   74    4      417   78    PD\n",
      "670   74    5      235   78    PD\n",
      "    pid task duration  age class\n",
      "7     0    8       10   72   HOA\n",
      "8     0  dot      680   72   HOA\n",
      "9     1    1       63   54   hoa\n",
      "10    1    2      202   54   hoa\n",
      "    pid task duration  age        class\n",
      "25    2    8       11   62  parkinson's\n",
      "26    2  dot      921   62  parkinson's\n",
      "27    3    1      178   57           PD\n",
      "28    3    2      221   57           PD\n"
     ]
    }
   ],
   "source": [
    "print(df.head(n=5))\n",
    "print(df.tail(n=5))\n",
    "print(df.ix[660:670])\n",
    "print(df.ix[7:10])\n",
    "print(df.ix[25:28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only look at the first 5 rows and the last 5 rows of the dataset, the columns looks like it is well formed with no missing values; however, we see the class column has inconsistent labels for our two classes (HOA and PD) and for pids 663, 664, 665 (among others) there is a \"?\" denoting a missing value. In fact, if we count the number of \"?\" in the duration column, we see that there are 10 tasks with missing durations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(df[\"duration\"].value_counts()[\"?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace the \"?\" with `NaN` values so we can more easily detect the fields with missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.replace(\"?\", np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74    9\n",
      "18    9\n",
      "20    9\n",
      "21    9\n",
      "22    9\n",
      "23    9\n",
      "24    9\n",
      "25    9\n",
      "26    9\n",
      "27    9\n",
      "28    9\n",
      "29    9\n",
      "30    9\n",
      "31    9\n",
      "32    9\n",
      "33    9\n",
      "34    9\n",
      "19    9\n",
      "17    9\n",
      "36    9\n",
      "16    9\n",
      "1     9\n",
      "2     9\n",
      "3     9\n",
      "4     9\n",
      "5     9\n",
      "6     9\n",
      "7     9\n",
      "8     9\n",
      "9     9\n",
      "     ..\n",
      "63    9\n",
      "64    9\n",
      "65    9\n",
      "66    9\n",
      "67    9\n",
      "68    9\n",
      "69    9\n",
      "70    9\n",
      "71    9\n",
      "72    9\n",
      "57    9\n",
      "55    9\n",
      "38    9\n",
      "54    9\n",
      "39    9\n",
      "40    9\n",
      "41    9\n",
      "42    9\n",
      "43    9\n",
      "44    9\n",
      "45    9\n",
      "46    9\n",
      "47    9\n",
      "48    9\n",
      "49    9\n",
      "50    9\n",
      "51    9\n",
      "52    9\n",
      "53    9\n",
      "0     9\n",
      "Name: pid, dtype: int64\n",
      "Number of NaN: 0\n",
      "***********************************************************************\n",
      "\n",
      "6      75\n",
      "3      75\n",
      "1      75\n",
      "dot    75\n",
      "7      75\n",
      "8      75\n",
      "2      75\n",
      "4      75\n",
      "5      75\n",
      "Name: task, dtype: int64\n",
      "Number of NaN: 0\n",
      "***********************************************************************\n",
      "\n",
      "9       29\n",
      "10      20\n",
      "11      18\n",
      "8       17\n",
      "7       12\n",
      "13      10\n",
      "6        8\n",
      "5        7\n",
      "12       7\n",
      "42       6\n",
      "15       5\n",
      "201      5\n",
      "214      5\n",
      "205      5\n",
      "222      5\n",
      "52       5\n",
      "255      4\n",
      "35       4\n",
      "48       4\n",
      "65       4\n",
      "34       4\n",
      "178      4\n",
      "216      4\n",
      "61       4\n",
      "31       4\n",
      "297      4\n",
      "224      4\n",
      "14       3\n",
      "18       3\n",
      "116      3\n",
      "        ..\n",
      "959      1\n",
      "159      1\n",
      "128      1\n",
      "592      1\n",
      "441      1\n",
      "258      1\n",
      "657      1\n",
      "600      1\n",
      "870      1\n",
      "98       1\n",
      "390      1\n",
      "1077     1\n",
      "155      1\n",
      "448      1\n",
      "310      1\n",
      "539      1\n",
      "411      1\n",
      "387      1\n",
      "1322     1\n",
      "631      1\n",
      "64       1\n",
      "146      1\n",
      "879      1\n",
      "366      1\n",
      "3513     1\n",
      "236      1\n",
      "4        1\n",
      "930      1\n",
      "500      1\n",
      "344      1\n",
      "Name: duration, dtype: int64\n",
      "Number of NaN: 10\n",
      "***********************************************************************\n",
      "\n",
      "70    72\n",
      "72    36\n",
      "62    36\n",
      "64    36\n",
      "65    36\n",
      "68    36\n",
      "54    36\n",
      "67    27\n",
      "56    27\n",
      "57    27\n",
      "76    27\n",
      "59    27\n",
      "80    18\n",
      "55    18\n",
      "60    18\n",
      "61    18\n",
      "87    18\n",
      "81    18\n",
      "83    18\n",
      "77    18\n",
      "85     9\n",
      "69     9\n",
      "66     9\n",
      "86     9\n",
      "89     9\n",
      "63     9\n",
      "88     9\n",
      "73     9\n",
      "75     9\n",
      "78     9\n",
      "79     9\n",
      "93     9\n",
      "Name: age, dtype: int64\n",
      "Number of NaN: 0\n",
      "***********************************************************************\n",
      "\n",
      "HOA            396\n",
      "PD             189\n",
      "healthy         27\n",
      "hoa             27\n",
      "parkinson's      9\n",
      "pd               9\n",
      "Parkinson        9\n",
      "Parkinson's      9\n",
      "Name: class, dtype: int64\n",
      "Number of NaN: 0\n",
      "***********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    ser = df[col]\n",
    "    print(ser.value_counts())\n",
    "    print(\"Number of NaN:\", ser.isnull().sum())\n",
    "    print(\"***********************************************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our exploration of the data, we know there are 10 null values in the duration column that we need handle. There are a few ways we do this:\n",
    "1. Remove the row and/or participant's data with missing information\n",
    "1. Fill the missing values. One way to do this is by filling each missing value with the average of \"similar\" instances (e.g. same task, same class, similar age).\n",
    "1. Leave it alone for now. Handle it on a case by case basis in the later stages of the data analysis pipeline.\n",
    "\n",
    "We are going to remove the rows with missing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: (675, 5)\n",
      "After cleaning: (665, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before cleaning:\", df.shape)  \n",
    "df.dropna(inplace=True)\n",
    "index = np.arange(0, len(df))\n",
    "df.set_index(index, inplace=True)\n",
    "print(\"After cleaning:\", df.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode Task\n",
    "Now, let's decode the integer values associated with the task column by replacing them with a more human-readable text label. We will use a dictionary to story the integer to string mappings for task codes and replace the integers with the strings in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pid                       task duration  age class\n",
      "0     0               Water Plants      146   72   HOA\n",
      "1     0  Fill Medication Dispenser      210   72   HOA\n",
      "2     0            Wash Countertop      241   72   HOA\n",
      "3     0             Sweep and Dust      328   72   HOA\n",
      "4     0                       Cook      229   72   HOA\n",
      "5     0                 Wash Hands       38   72   HOA\n",
      "6     0                Perform TUG       10   72   HOA\n",
      "7     0    Perform TUG w/Questions       10   72   HOA\n",
      "8     0               Day Out Task      680   72   HOA\n",
      "9     1               Water Plants       63   54   hoa\n",
      "10    1  Fill Medication Dispenser      202   54   hoa\n"
     ]
    }
   ],
   "source": [
    "task_decoder = {\"1\": \"Water Plants\", \"2\": \"Fill Medication Dispenser\", \"3\": \"Wash Countertop\", \\\n",
    "               \"4\": \"Sweep and Dust\", \"5\": \"Cook\", \"6\": \"Wash Hands\", \"7\": \"Perform TUG\", \\\n",
    "               \"8\": \"Perform TUG w/Questions\", \"dot\": \"Day Out Task\"}\n",
    "\n",
    "def decode_task(df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    ser = df[\"task\"]\n",
    "    for key in task_decoder:\n",
    "        ser.replace(key, task_decoder[key], inplace=True)\n",
    "decode_task(df)\n",
    "print(df.head(n=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data frame now, we see that the task category is much more readable. This will be especially useful for generating plots with task labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Numeric Data Types\n",
    "Now, let's check out the data types for our two numeric columns, duration and age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"duration\"].dtype)\n",
    "print(df[\"age\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the age column is an integer type, but the duration column is an object type. This means that Pandas was unable to infer this column contained all integers when it was read in, which makes sense since we know there were \"?\"s in the duration column. Since we have replaced the \"?\" with `NaN`, let's convert it to integer now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "df[\"duration\"] = df[\"duration\"].astype(np.int)\n",
    "print(df[\"duration\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Class\n",
    "Lastly, we are going to clean the class column. This column is quite messy compared to the other columns we have worked with. We will use a simple rule based system to handle the various spellings and word choices that represent \"HOA\" and \"PD\".\n",
    "\n",
    "Note: If there are entries that we cannot classify as one of the above labels, we will overwrite the entry with a null value (`NaN`) to represent missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pid                       task  duration  age class\n",
      "0    0               Water Plants       146   72   HOA\n",
      "1    0  Fill Medication Dispenser       210   72   HOA\n",
      "2    0            Wash Countertop       241   72   HOA\n",
      "3    0             Sweep and Dust       328   72   HOA\n",
      "4    0                       Cook       229   72   HOA\n",
      "HOA    446\n",
      "PD     219\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def clean_class(df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    ser = df[\"class\"].copy()\n",
    "    \n",
    "    for i in range(0, len(ser), 1):\n",
    "        curr = str(ser[i])\n",
    "        curr = curr.lower()\n",
    "        if \"hoa\" in curr or \"healthy\" in curr:\n",
    "            ser[i] = \"HOA\"\n",
    "        elif \"pd\" in curr or \"parkinson\" in curr:\n",
    "            ser[i] = \"PD\"\n",
    "        elif \"unknown\" in curr:\n",
    "            ser[i] = \"?\"\n",
    "        else:\n",
    "            print(\"Unrecognized status: %d, %s\" %(i, ser[i]))\n",
    "            ser[i] = np.NaN\n",
    "        \n",
    "    df[\"class\"] = ser\n",
    "\n",
    "clean_class(df)\n",
    "print(df.head())\n",
    "print(df[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will write the cleaned data frame out to a new file. Our dataset is now cleaned and ready for use in the next step of our data analysis pipeline. Depending on what we want to do with the data, this could be continuing exploration by generating visualizations of the data, or perhaps scaling the features in preparation for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_fname = r\"files\\pd_hoa_activities_cleaned.csv\"\n",
    "df.to_csv(out_fname, index=False) # don't write out the index column"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
