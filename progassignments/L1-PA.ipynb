{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [AHA! Activity Health Analytics](http://casas.wsu.edu/)\n",
    "[Center for Advanced Studies of Adaptive Systems (CASAS)](http://casas.wsu.edu/)\n",
    "\n",
    "[Washington State University](https://wsu.edu)\n",
    "# L1-PA Pandas and K-Means Clustering (100 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Write object-oriented Python code\n",
    "* Use the `pandas` library\n",
    "* Implement k-means clustering\n",
    "* Analyze a real-world dataset\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Write Python code that utilizes:\n",
    "    * File I/O\n",
    "    * Strings\n",
    "    * Lists\n",
    "    * Command line arguments\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* [Pandas website](http://pandas.pydata.org/)\n",
    "* [k-Means Clustering](https://www.engage-csedu.org/find-resources/k-means-clustering) assignment by Chris Bailey-Kellogg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Overview and Requirements\n",
    "For this programming assignment, we are going to implement the [k-means clustering algorithm](https://en.wikipedia.org/wiki/K-means_clustering) in Jupyter Notebook. Cluster analysis seeks to separate objects into groups (or clusters), such that the objects within a group are more similar to each other than they are to objects in other groups. For example, we could cluster students by locations of their hometowns, stocks by a list of their closing prices over some interval of time, news articles based on the similarity of the words they contain, or types of cancer based on the profiles of genes that are active.\n",
    "\n",
    "This problem set studies cluster analysis of data defined by an array of numerical feature values. So a student's hometown location array might just have a latitude and longitude. A stock's array would have a price for each day. For news story aggregation, each article might have the numbers of occurrences of various words. And for the example dataset that we'll actually use here, each patient will be characterized by an array of gene expression levels, indicating for each gene a kind of relative abundance for that patient.\n",
    "\n",
    "The goal will be to take a set of such samples and find common groups (k of them!).\n",
    "\n",
    "## Program Details\n",
    "### Background: Samples\n",
    "A sample has a name and an array of values. We will will view each index in the array as a dimension, and will think of an array of n samples as an n-dimensional point. For example, [simple.csv](https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/files/simple.csv):\n",
    "\n",
    "|Sample|Feature #1|Feature #2|Feature #3|Feature #4|Feature #5|Features #6|Feature #7|Feature #8|Feature #9|Feature #10|\n",
    "|-|-|-|-|\n",
    "|g0|0  |0.1|0.2|0  |0.4|0.5|0.6|0.7|0.8|0.9|\n",
    "|g1|1.0|0.9|0.8|0.7|0.6|0.5|0.4|0.3|0  |0.1|\n",
    "|g2|0.1|0.2|0.3|0.4|0.5|0.6|0.7|0.8|0.9|1.0|\n",
    "|g3|0.4|0.4|0.4|0.4|0.4|0.4|0.4|0.4|0.4|0.4|\n",
    "|g4|0.9|0.8|0.7|0.6|0.5|0.4|0.3|0.2|0.1|0.0|\n",
    "|g5|0.5|0  |0.5|0.5|0.5|0.5|0.5|0.5|0.5|0.5|\n",
    "\n",
    "To visualize samples all together, we'll use a heat map with a blue-red color scale, from blue for low values up to red for high values, with white in the middle:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/figures/simple_csv_heatmap.png\" width=\"400\" />\n",
    "\n",
    "Upon rearranging the samples, we can see three different groups in in this toy example (separated by a black line):\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/figures/simple_csv_heatmap_clustered.png\" width=\"400\" />\n",
    "\n",
    "### Background: K-means Clustering\n",
    "One way to cluster objects is called k-means clustering. The goal is to find k different clusters, each represented by a \"prototype\", defined as the centroid of cluster. The centroid is computed as follows: the jth value in the centroid is the mean (average) of the jth values of all the members of the cluster. Our goal is for every member a cluster to be closer to that cluster's prototype than to any of the other prototypes. Thus a prototype is a good representative for the items in a cluster.\n",
    "\n",
    "We start the algorithm with k initial clusters and centroids. We then alternate between two steps:\n",
    "1. For each sample, find the nearest prototype. This assigns members to each cluster.\n",
    "1. Set the prototype of each cluster as the centroid of its members.\n",
    "\n",
    "We stop when the cluster assignment doesn't change, or when we've reached a maximum number of iterations. \n",
    "\n",
    "Note: In June of 2009 a paper was published that showed that in the worst case the time for k-means to converge can be exponential ([Vattani, 2009](http://cseweb.ucsd.edu/~avattani/papers/kmeans-journal.pdf)), but that's rare in practice, and not a problem in this assignment.\n",
    "\n",
    "There are many ways to initialize K-means. We will use a random approach: for each sample, assign it to a randomly selected cluster. So create a list of clusters (each of which has a list of its members). The members lists start off empty, and we just go through the samples, randomly choosing a cluster to assign them to.\n",
    "\n",
    "Once members are assigned to a cluster, the cluster can set its prototype as the centroid. Each iteration produces a new set of clusters, by assigning the samples according to the closest prototypes. An easy way to do this is, for each sample, to determine which index into the old clusters list has the closest prototype to the sample, and then add the sample to the cluster of the same index in the new clusters list. Closest is again just by [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance):\n",
    "\n",
    "$$d(\\mathbf{p}, \\mathbf{q}) = d(\\mathbf{q}, \\mathbf{p}) = \\sqrt{(q_{1} - p_{1})^{2} + (q_{2} - p_{2})^{2} + ... + (q_{n} - p_{n})^{2}} = \\sqrt{\\sum_{i=1}^{n}(q_{i} - p_{i})^{2}}$$\n",
    "\n",
    "where $\\mathbf{p}$ and $\\mathbf{q}$ are equal length vectors.\n",
    "\n",
    "You are to write your own Euclidean distance function; however, you can check your work with the [Scipy `euclidean` function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html).\n",
    "\n",
    "The process iterates until it reaches convergence, that is the membership of samples to clusters does not change from iteration to the next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "In addition to the simple test dataset, you are to run your code on a real dataset on which clustering was performed to gain real insight. This data was published in the paper by van't Veer et al., [\"Gene expression profiling predicts clinical outcome of breast cancer\"](https://www.ncbi.nlm.nih.gov/pubmed/11823860) in Nature 2002, 415:530-536. A preprocessed and filtered version is provided as an example for the Matlab bioinformatics toolkit. Chris Bailey-Kellogg then did a little more preprocessing (normalizing the data) to form the dataset we will use: [cancer.csv](https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/files/cancer.csv). Each row in the array corresponds to a different patient, labeled as either having a recurrence of cancer or not. The columns are different genes, and the values how much more or less the gene is represented in that patient (a subset of divergent genes have been preselected). The question then is whether there is a distinctive pattern of gene expression between the two classes of patient.\n",
    "\n",
    "Heat map of [cancer.csv](https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/files/cancer.csv):\n",
    "<img src=\"https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/figures/cancer_csv_heatmap.png\" width=\"400\" />\n",
    "\n",
    "Heat map of [cancer.csv](https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/files/cancer.csv) after 2-means clustering:\n",
    "<img src=\"https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/figures/cancer_csv_heatmap_clustered.png\" width=\"400\" />\n",
    "\n",
    "The two clusters are separated by a black line in the figure. We see that one group of subjects has more blue in the left bunch of genes (columns) while the other has more red, and vice-versa in the right bunch of genes. These genes appear to be some \"fingerprint\" distinguishing the two classes of patients (they were selected for that distinction).\n",
    "\n",
    "Note: the simple made-up case for initial testing is [simple.csv](https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/files/simple.csv); the real dataset is [cancer.csv](https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/files/cancer.csv).\n",
    "\n",
    "### Data Storage\n",
    "Read in the gene expression dataset into a `pandas` dataframe using [`read_csv()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). The first column in the input file is the index. The columns are unlabeled.\n",
    "\n",
    "### Program Output\n",
    "Store the k-means clustering results in a data frame with rows corresponding to each cluster (there will be k of clusters, hence k rows) and columns corresponding to each feature. For example, for [simple.csv](https://raw.githubusercontent.com/gsprint23/aha/master/progassignments/files/simple.csv), the cluster results data frame is as follows (k = 3, N = 5):\n",
    "\n",
    "||1|2|3|4|5|6|7|8|9|10|\n",
    "|-|-|-|-|-|-|-|-|-|-|-|\n",
    "|0|0.05|  0.15|  0.25|   0.2|  0.45|  0.55|  0.65|  0.75|  0.85|  0.95|\n",
    "|1|0.95|  0.85|  0.75|  0.65|  0.55|  0.45|  0.35|  0.25|  0.05|  0.05|\n",
    "|2|0.45|   0.2|  0.45|  0.45|  0.45|  0.45|  0.45|  0.45|  0.45|  0.45|\n",
    "\n",
    "Use the [`to_csv()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.to_csv.html) keyword `float_format=\"%.2f\"` to match the format above.\n",
    "\n",
    "### Command Line Arguments\n",
    "Your program should accept the following parameters as command line arguments (in this order):\n",
    "1. Input filename: the filename (relative path) of the input data specified\n",
    "1. Output filename: the filename (relative path) of the output data specified\n",
    "1. k: number of clusters to create in K-means clustering\n",
    "1. N: maximum number of iterations\n",
    "\n",
    "Example: `files\\simple.csv files\\simple_results.csv 3 5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "For your assignment submission, turn in a .zip file with the following files:\n",
    "1. main.py file with a `main()` function that drives your program\n",
    "1. Two .csv files\n",
    "    1. simple.csv results\n",
    "    1. cancer.csv results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 100 points. Your assignment will be evaluated based on a successful compilation and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 5 pts for correctly extracting program parameters from command line arguments\n",
    "* 10 pts for correctly storing the sample data in a `DataFrame`\n",
    "* 10 pts for correctly initializing random clusters (ensure an empty cluster does not exist)\n",
    "* 10 pts for correctly computing the Euclidean distance\n",
    "* 10 pts for correctly computing cluster prototype (centroid)\n",
    "* 10 pts for correctly determining the closest prototype\n",
    "* 15 pts for correctly re-clustering using iteration\n",
    "* 10 pts for correctly implementing the re-clustering convergence condition\n",
    "* 15 pts for correctly writing the results to a file\n",
    "* 5 pts for adherence to proper programming style and comments established for the class"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
